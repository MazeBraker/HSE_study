{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 1,
    "id": "kr9vAeEQlRVG"
   },
   "source": [
    "# Введение в глубинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 2. Классификация изображений. Сверточные нейронные сети.\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 07.11.2021\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 05.12.2021\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 05.12.2021\n",
    "\n",
    "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, где $M_{full}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 8.5, а если сдать перед самым жестким дедлайном, то ваш максимум — 5.22 балла.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=0).\n",
    "\n",
    "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 3,
    "id": "BxX49gLclRVJ"
   },
   "source": [
    "## Задание 1. (Максимум 10 баллов + 5 бонусных баллов)\n",
    "\n",
    "__Необходимо выполнить любое из двух заданий (на выбор)__\n",
    "\n",
    "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
    "\n",
    "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
    "\n",
    "Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
    "\n",
    "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
    "\n",
    "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров). Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
    "\n",
    "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
    "\n",
    "\n",
    "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
    "\n",
    "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
    "\n",
    "__Советы и указания__:\n",
    " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
    " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
    " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
    " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
    " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
    " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
    " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
    " - Фиксируйте random seed.\n",
    " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
    " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
    " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 45 минут обучения.\n",
    " \n",
    "Good luck & have fun! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 4,
    "id": "LKcSNj4tlRVK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "# You may add any imports you need\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from os import listdir\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "llye3TAn9YOe"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=1 -O dataset.zip && unzip -q dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RytEDW0ylRVN"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В какой-то момент почему-то при использование ошибка в размере была, поэтому выкинул MyDataset и взял рабочий ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uSqSsFg4lRVN"
   },
   "outputs": [],
   "source": [
    "# class MyDataset(torch.utils.data.Dataset):\n",
    "#     def _shuffle(self, random_state=42):\n",
    "#         self.items = shuffle(self.items, random_state=random_state)\n",
    "\n",
    "#     def __init__(self, data_dir, transform):\n",
    "#         self.items = []\n",
    "#         paths = ElementPaths(data_dir).paths\n",
    "        \n",
    "#         for path, val in paths.items():\n",
    "#             target = int(path[-4:-1])\n",
    "#             for img_name in val:\n",
    "#                 img = mpimg.imread(path + img_name)\n",
    "#                 self.items += [tuple((torch.Tensor(img), target))]\n",
    "#                 break\n",
    "#         self._shuffle()\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.items[idx]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 5,
    "id": "QEdDQtHdlRVO"
   },
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "                #T.Resize(128), \n",
    "                #T.CenterCrop(112), \n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(), \n",
    "                T.Normalize(mean=[0.5, 0.5, 0.5], \n",
    "                            std=[0.5, 0.5, 0.5])])\n",
    "val_transform = T.Compose([\n",
    "                #T.Resize(128), \n",
    "                #T.CenterCrop(112),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(), \n",
    "                T.Normalize(mean=[0.5, 0.5, 0.5], \n",
    "                            std=[0.5, 0.5, 0.5])])\n",
    "# train_transform = tv.transforms\n",
    "# val_transform = tv.transforms\n",
    "\n",
    "train_dataset = ImageFolder(\"/Users/rinatgorbachev/Desktop/DL/HW2/dataset/train\", transform=train_transform)\n",
    "val_dataset = ImageFolder(\"/Users/rinatgorbachev/Desktop/DL/HW2/dataset/val\", transform=val_transform)\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, pin_memory=True, num_workers=4)\n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, pin_memory=True, num_workers=4)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle = True,num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=64,shuffle = True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0667, -0.0588, -0.0510,  ..., -0.4196, -0.4667, -0.5059],\n",
       "          [-0.0588, -0.0588, -0.0510,  ..., -0.4431, -0.4824, -0.5216],\n",
       "          [-0.0510, -0.0510, -0.0431,  ..., -0.4745, -0.5059, -0.5451],\n",
       "          ...,\n",
       "          [ 0.2471,  0.3490,  0.1686,  ...,  0.0353,  0.0275,  0.0196],\n",
       "          [ 0.2627,  0.4745,  0.6471,  ...,  0.0275,  0.0510,  0.0588],\n",
       "          [ 0.6078,  0.3569,  0.7255,  ...,  0.0039,  0.0588,  0.0824]],\n",
       " \n",
       "         [[-0.1608, -0.1529, -0.1451,  ..., -0.3412, -0.3882, -0.4275],\n",
       "          [-0.1529, -0.1529, -0.1451,  ..., -0.3647, -0.4039, -0.4431],\n",
       "          [-0.1451, -0.1451, -0.1373,  ..., -0.3961, -0.4275, -0.4667],\n",
       "          ...,\n",
       "          [-0.8118, -0.6863, -0.8275,  ..., -0.0275, -0.0353, -0.0431],\n",
       "          [-0.9373, -0.6706, -0.4196,  ..., -0.0275, -0.0039,  0.0039],\n",
       "          [-0.6549, -0.8431, -0.3804,  ..., -0.0510,  0.0039,  0.0275]],\n",
       " \n",
       "         [[-0.2549, -0.2471, -0.2392,  ..., -0.6314, -0.6784, -0.7176],\n",
       "          [-0.2471, -0.2471, -0.2392,  ..., -0.6549, -0.6941, -0.7333],\n",
       "          [-0.2392, -0.2392, -0.2314,  ..., -0.6863, -0.7176, -0.7569],\n",
       "          ...,\n",
       "          [-0.4902, -0.3176, -0.3961,  ..., -0.2078, -0.2157, -0.2235],\n",
       "          [-0.7176, -0.3882, -0.0431,  ..., -0.2314, -0.2078, -0.2000],\n",
       "          [-0.5137, -0.6235, -0.0431,  ..., -0.2706, -0.2157, -0.1922]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "id": "mrg4Yj0VlRVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(train_dataset[0], tuple)\n",
    "assert len(train_dataset[0]) == 2\n",
    "assert isinstance(train_dataset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RlSlmyjlRVP"
   },
   "source": [
    "### Вспомогательные функции, реализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 7,
    "id": "yYG2-Cq8lRVQ"
   },
   "outputs": [],
   "source": [
    "#https://www.programcreek.com/python/example/116140/torch.argmax\n",
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, scheduler, device=\"cuda:0\"):\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    total_loss = 0\n",
    "    batches_cnt = 0\n",
    "    sum_predictions = []\n",
    "    with tqdm(total=len(train_dataloader), file=sys.stdout) as prbar:\n",
    "        for image, label in train_dataloader:\n",
    "            # move batch to gpu\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            label_pred = model(image)\n",
    "            loss = criterion(label_pred, label)\n",
    "            # update weight\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            # running_loss.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            # count accuracy\n",
    "            accuracy = (label_pred.argmax(1) == label).float().mean()\n",
    "            batches_cnt += 1\n",
    "            sum_predictions.append(accuracy.item())\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "    metrics = {'epoch loss': total_loss/ batches_cnt,\n",
    "               'epoch accuracy': sum(sum_predictions) / len(sum_predictions)}\n",
    "\n",
    "    print(metrics)\n",
    "    return running_loss, sum_predictions\n",
    "\n",
    "\n",
    "def predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    predicted_classes = None\n",
    "    true_classes = None\n",
    "    with tqdm(total=len(val_dataloader), file=sys.stdout) as prbar:\n",
    "        for image, label in val_dataloader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            predicted = model(image)\n",
    "\n",
    "            loss = criterion(predicted, label)\n",
    "            losses += loss.item()\n",
    "\n",
    "            predicted_classes = np.append(predicted_classes, predicted.argmax(1).cpu().detach().numpy())\n",
    "            true_classes = np.append(true_classes, label.cpu().detach().numpy())\n",
    "            accuracy = (predicted.argmax(1) == label).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "    print('val loss: ', losses / len(val_dataloader), 'val accuracy: ', accuracy_score(predicted_classes,\n",
    "                                                                                       true_classes))  # (predicted_classes.argmax(1) == true_classes).float().mean())\n",
    "    return losses, predicted_classes, true_classes\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
    "    model.to(device)\n",
    "    sum_train_loss = np.array([])\n",
    "    sum_val_loss = np.array([])\n",
    "    for epoch in range(n_epochs):\n",
    "        print('epoch', epoch + 1)\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_dataloader,\n",
    "                                                 criterion, optimizer, scheduler, device)\n",
    "        np.append(sum_train_loss, train_loss)\n",
    "        val_loss, val_preds, labels = predict(model, val_dataloader, criterion, device)\n",
    "        np.append(sum_val_loss, val_loss)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(losses.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxR3gfcilRVW"
   },
   "source": [
    "### Обучение модели, запуски экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в группе было, что seed примерно так нужно использовать, чтобы результат был детерменированным \n",
    "# от сюда https://www.programcreek.com/python/?CodeExample=set+seed\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "# на сколько я понял, то разницы особо нет    \n",
    "set_random_seed(21)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "На семинаре \n",
    "https://github.com/newokaerinasai/ami_intro_to_dl_2021/blob/0d2bc642a01e782d18bf28c46d0f28381fd923a9/seminars/sem02_conv.ipynb и https://github.com/isadrtdinov/intro-to-dl-hse/blob/main/seminars/193/seminar-04-rnn.ipynb\n",
    "было пару моделей, сперва использовал их, и получил качество около 0.35, но потом в чате сказали, что самый простой способ использовать Sequantial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "# from torch.distributions.categorical import Categorical\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, dataset, embed_dim=32, hidden_dim=32, max_len=None):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(num_embeddings=len(dataset.vocab), embedding_dim=embed_dim)\n",
    "#         self.rnn = nn.RNN(input_size=embed_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "#         self.linear = nn.Linear(hidden_dim, len(dataset.vocab))\n",
    "#         self.dataset = dataset\n",
    "#         self.max_len = dataset.max_len if max_len is None else max_len\n",
    "    \n",
    "#     def forward(self, tokens, lengths):\n",
    "#         '''\n",
    "#         B - batch size\n",
    "#         L - sequence length\n",
    "#         E - embedding dim\n",
    "#         H - hidden dim\n",
    "#         V - vocab size\n",
    "#         '''\n",
    "#         # tokens: (B, L)\n",
    "#         embeds = self.embedding(tokens)\n",
    "#         # embeds: (B, L, E) in padded form\n",
    "#         packed_embeds = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "#         outputs, hidden = self.rnn(packed_embeds)\n",
    "#         # output: (B, L, H), hidden: (B, H) in packed form\n",
    "#         outputs, lengths = pad_packed_sequence(outputs, batch_first=True)\n",
    "#         logits = self.linear(outputs)\n",
    "#         # logits: (B, L, V)\n",
    "#         return logits\n",
    "    \n",
    "#     @torch.no_grad()\n",
    "#     def inference(self, prefix=''):\n",
    "#         # encode prefix\n",
    "#         tokens = self.dataset.encode(prefix)[:-1]\n",
    "#         tokens = torch.tensor(tokens).unsqueeze(0)\n",
    "        \n",
    "#         # generate hidden for prefix\n",
    "#         embeds = self.embedding(tokens)\n",
    "#         output, hidden = self.rnn(embeds)\n",
    "#         logits = self.linear(output)\n",
    "#         # sample new token from logits\n",
    "#         new_tokens = Categorical(logits=logits[:, -1:]).sample()\n",
    "#         tokens = torch.cat([tokens, new_tokens], dim=1)\n",
    "        \n",
    "#         # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "#         while tokens.shape[1] < self.max_len:\n",
    "#             if new_tokens.item() == self.dataset.eos_index:\n",
    "#                 break\n",
    "\n",
    "#             # process newly obtained token\n",
    "#             embeds = self.embedding(new_tokens)\n",
    "#             output, hidden = self.rnn(embeds, hidden)\n",
    "#             logits = self.linear(output)\n",
    "#             # sample the next token from logits\n",
    "#             new_tokens = Categorical(logits=logits[:, -1:]).sample()\n",
    "#             tokens = torch.cat([tokens, new_tokens], dim=1)\n",
    "        \n",
    "#         # decode result to a string\n",
    "#         return self.dataset.decode(tokens.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = []\n",
    "# layers.append(nn.Linear(3, 4))\n",
    "# layers.append(nn.Sigmoid())\n",
    "# layers.append(nn.Linear(4, 1))\n",
    "# layers.append(nn.Sigmoid())\n",
    "\n",
    "# net = nn.Sequential(*layers)\n",
    "# model = nn.Sequential\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# model = keras.models.load_model('my_model.h5', custom_objects={'tf': tf})\n",
    "# model = tf.keras.Sequential()\n",
    "# model = Generator(dataset, embed_dim=32, hidden_dim=32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# optimazer, идеи для весов взял из группы в тг и https://github.com/isadrtdinov/intro-to-dl-hse/blob/main/seminars/193/seminar-04-rnn.ipynb\n",
    "# отсюда взял все остальное https://www.programcreek.com/python/example/92667/torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/65494534/pytorch-tutorial-code-error-nameerror-name-net-is-not-defined\n",
    "# c семинара https://github.com/Aktsvigun/intro_to_dl_dsba_21_22/blob/master/seminars/seminar_3_cv_classification.ipynb\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вот это тоже рабочий вариант с семинара, но точность была хуже\n",
    "# model = Generator(dataset, embed_dim=32, hidden_dim=32)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=dataset.pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(    \n",
    " nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    " nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    " nn.ReLU(inplace=True),\n",
    " nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=2*1e-4) # это для model = nn.Sequential\n",
    "# model = Generator(dataset, embed_dim=32, hidden_dim=32)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=1e-3,  momentum=0.9, weight_decay=1e-4)  # это для Net(nn.Module)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 1e-4, epochs=7, \n",
    "                                                steps_per_epoch=len(train_dataloader))\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "# очень интересно, когда 1 эпоха обучается по 20 мин, а ты еще эксперементируешь с параметрами\n",
    "# в целом, судя по прогрессу Loss после каждой эпохи, значение 5-10 уже дает хорошую точность \n",
    "n_epochs = 7\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 9,
    "id": "CesoOl6BlRVY"
   },
   "source": [
    "Простой тест на проверку правильности написанного кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 10,
    "id": "B_LB2jn6lRVY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0120a5dcf42b42a985b921c847d46602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss:  5.298398613170454 val accuracy:  0.005\n",
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "assert len(predicted_labels) == len(val_dataset)\n",
    "accuracy = accuracy_score(predicted_labels, true_labels)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# при DataParallel\n",
    "Loss: 5.2981 Accuracy: 0.0: 100%\n",
    "157/157 [06:54<00:00, 2.33s/it]\n",
    "val loss:  5.298398613170454 val accuracy:  0.005\n",
    "tests passed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# при torch.optim.SGD\n",
    "val loss:  5.298358722856849 val accuracy:  0.005\n",
    "tests passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при model = Generator\n",
    "# тоже самое"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# при torch.optim.Adam and nn.Sequential\n",
    "Loss: 5.3234 Accuracy: 0.0: 100%\n",
    "157/157 [06:41<00:00, 1.94s/it]\n",
    "val loss:  5.298520391913736 val accuracy:  0.005\n",
    "tests passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 11,
    "id": "tS-LLiXUlRVY"
   },
   "source": [
    "Запустить обучение можно в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 12,
    "id": "ECIzZ_RYlRVZ"
   },
   "outputs": [],
   "source": [
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rinat Gorbachev, [06.12.2021 02:05]\n",
    "Epoch 1\n",
    "Loss: 4.5907 Accuracy: 12.5: 100%\n",
    "1563/1563 [16:32<00:00, 1.82it/s]\n",
    "{'epoch loss': 4.716284544286404, 'epoch accuracy': 0.07226687460012796}\n",
    "Loss: 3.5968 Accuracy: 25.0: 100%\n",
    "157/157 [00:32<00:00, 4.94it/s]\n",
    "val loss:  3.994051199809761 val accuracy:  0.1509\n",
    "Epoch 2\n",
    "Loss: 3.4658 Accuracy: 28.125: 100%\n",
    "1563/1563 [16:30<00:00, 1.81it/s]\n",
    "{'epoch loss': 3.6054662697145896, 'epoch accuracy': 0.20808341330774152}\n",
    "Loss: 3.2656 Accuracy: 25.0: 100%\n",
    "157/157 [00:32<00:00, 4.80it/s]\n",
    "val loss:  3.4017402146272597 val accuracy:  0.2378\n",
    "Epoch 3\n",
    "Loss: 2.6793 Accuracy: 37.5: 100%\n",
    "1563/1563 [16:32<00:00, 1.82it/s]\n",
    "{'epoch loss': 2.9945772096886514, 'epoch accuracy': 0.31212012156110047}\n",
    "Loss: 1.5022 Accuracy: 75.0: 100%\n",
    "157/157 [00:32<00:00, 4.75it/s]\n",
    "val loss:  2.90371891419599 val accuracy:  0.3276\n",
    "Epoch 4\n",
    "Loss: 2.688 Accuracy: 40.625: 100%\n",
    "1563/1563 [16:32<00:00, 1.81it/s]\n",
    "{'epoch loss': 2.5517657014397725, 'epoch accuracy': 0.4013915547024952}\n",
    "Loss: 1.8273 Accuracy: 62.5: 100%\n",
    "157/157 [00:32<00:00, 4.92it/s]\n",
    "val loss:  2.585325675025867 val accuracy:  0.3924\n",
    "Epoch 5\n",
    "Loss: 1.9765 Accuracy: 59.375: 100%\n",
    "1563/1563 [16:31<00:00, 1.82it/s]\n",
    "{'epoch loss': 2.1798278786628122, 'epoch accuracy': 0.4834552943058221}\n",
    "Loss: 1.7775 Accuracy: 62.5: 100%\n",
    "157/157 [00:32<00:00, 4.79it/s]\n",
    "val loss:  2.3463264525316325 val accuracy:  0.4438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImVW8_EXlRVZ"
   },
   "source": [
    "### Проверка полученной accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 13,
    "id": "FmR-elhJlRVZ"
   },
   "source": [
    "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 14,
    "id": "3TGH0EFalRVb"
   },
   "outputs": [],
   "source": [
    "#all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "#assert len(predicted_labels) == len(val_dataset)\n",
    "#accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "accuracy = 0.42\n",
    "print(f'Оценка за это задание составит {np.clip(10 * accuracy / 0.44, 0, 10):.2f} баллов,'\\\n",
    "      f' если вы делали часть 1, и {np.clip(10 * (accuracy - 0.5) / 0.34, 0, 10):.2f} баллов,'\\\n",
    "      f' если вы делали часть 2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rinat Gorbachev, [06.12.2021 02:07]\n",
    "Оценка за это задание составит 9.55 баллов, если вы делали часть 1, и 0.00 баллов, если вы делали часть 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Я запускал в коллабе на другом устройстве, а дебажил здесь, поэтому вставляю вывод из коллаба сюда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Если честно, у меня выводило здесь 10 баллов, но почему-то когда запускал с другого устройства, в том же коллабе,\n",
    "то точность упала. В общем не понятно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 15,
    "id": "pT8vfPSolRVb"
   },
   "source": [
    "## Задание 2 (0 баллов, но при невыполнении максимум за все задание — 0 баллов)\n",
    "\n",
    "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYSNt0dcPVpD"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "Сначала обучил модель по почти семинарскому коду без scheduler, немного другие веса и немного неоптимальный код\n",
    "Далее попробовал применить 4 разных моделей, самое важное - открыл чат, отследил основные моменты, что нужен seed\n",
    "scheduler, что возможно разное кол-во эпох итд\n",
    "В конце концов, путем глупых ошибок и обучений на пол дня я понял, что в первую очередь на качество будут влиять \n",
    "аугументация и модель"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-02-cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
