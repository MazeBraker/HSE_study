{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3, Лупашин Евгений, БПМИ184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category-encoders\n",
      "  Downloading category_encoders-2.4.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 345 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from category-encoders) (0.12.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/rinat/anaconda3/lib/python3.9/site-packages (from category-encoders) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from category-encoders) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from category-encoders) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/rinat/anaconda3/lib/python3.9/site-packages (from category-encoders) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from category-encoders) (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/rinat/anaconda3/lib/python3.9/site-packages (from pandas>=0.21.1->category-encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/rinat/anaconda3/lib/python3.9/site-packages (from pandas>=0.21.1->category-encoders) (2021.3)\n",
      "Requirement already satisfied: six in /home/rinat/anaconda3/lib/python3.9/site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/rinat/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category-encoders) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category-encoders) (2.2.0)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.4.0\n",
      "Requirement already satisfied: sweetviz in /home/rinat/anaconda3/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (1.7.1)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (5.6.0)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (1.3.4)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (2.11.3)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (4.62.3)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /home/rinat/anaconda3/lib/python3.9/site-packages (from sweetviz) (3.4.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from importlib-resources>=1.2.0->sweetviz) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/rinat/anaconda3/lib/python3.9/site-packages (from jinja2>=2.11.1->sweetviz) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/rinat/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/rinat/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rinat/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rinat/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (0.10.0)\n",
      "Requirement already satisfied: six in /home/rinat/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.1.3->sweetviz) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/rinat/anaconda3/lib/python3.9/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2021.3)\n",
      "Collecting dtale\n",
      "  Downloading dtale-2.2.0-py2.py3-none-any.whl (12.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.7 MB 41 kB/s eta 0:00:013\n",
      "\u001b[?25hRequirement already satisfied: six in /home/rinat/anaconda3/lib/python3.9/site-packages (from dtale) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn==0.24.2 in /home/rinat/anaconda3/lib/python3.9/site-packages (from dtale) (0.24.2)\n",
      "Requirement already satisfied: future>=0.14.0 in /home/rinat/anaconda3/lib/python3.9/site-packages (from dtale) (0.18.2)\n",
      "Collecting Flask-Compress\n",
      "  Downloading Flask_Compress-1.11-py3-none-any.whl (7.9 kB)\n",
      "Collecting dash>=2.0.0\n",
      "  Downloading dash-2.3.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 543 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: seaborn in /home/rinat/anaconda3/lib/python3.9/site-packages (from dtale) (0.11.2)\n",
      "Collecting dash-colorscales\n",
      "  Downloading dash_colorscales-0.0.4.tar.gz (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 62 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-4.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |█▉                              | 71 kB 735 kB/s eta 0:00:02"
     ]
    }
   ],
   "source": [
    "! pip install category-encoders\n",
    "! pip install sweetviz\n",
    "! pip install dtale\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "import dtale\n",
    "%matplotlib inline\n",
    "from category_encoders.woe import WOEEncoder\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "df_acc = pd.read_csv(\"12_accept.csv\")\n",
    "df_rej = pd.read_csv(\"12_reject.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первые строки заявок в accept\n",
    "print('Размер accept:', df_acc.shape[0])\n",
    "print('Размер reject:', df_rej.shape[0])\n",
    "df_acc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Какая доля 1 в выборке \"accept\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc[df_acc.target == 1].shape[0] / df_acc.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Статистики по переменным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо рассчитать для всех интервальных переменных следующее:\n",
    " - Доля пропущенных значений \n",
    " - Медиана\n",
    " - Среднее\n",
    " - Среднеквадратическое отклонение\n",
    " - Есть ли аномальные значения, выбросы? \n",
    " - Information Value\n",
    " \n",
    " \n",
    "Необходимо рассчитать для всех категориальных переменных следующее:\n",
    " - Мода\n",
    " - Доля пропущенных значений\n",
    " - Information Value\n",
    " - Есть ли выбросы, аномальные значений\n",
    " \n",
    " \n",
    "На всё, кроме выбросов и IV ответит отчёт, который генерируется в следующей клетке (`report.html`). По нажатию на признак видны его основные показатели. Выбросы далее тоже будем оценивать исходя из отчёта. Information Value для всех переменных и для всех датасетов посчитаем после обучения модели для разметки reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сразу удалим бесполезный столбец UID\n",
    "df_acc.drop(columns='UID', inplace=True)\n",
    "df_rej.drop(columns='UID', inplace=True)\n",
    "\n",
    "report = sv.compare([df_acc, \"AcceptDF\"], [df_rej, \"RejectDF\"], \"target\")\n",
    "report.show_html('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что насчёт выбросов?\n",
    "\n",
    "Есть люди с доходом, превышающим 500000. Очевидно, таких людей мы будем относить к одной какой-то категории `богачи`, запомнили.\n",
    "\n",
    "CNT_MNTH_FROM_LAST_PMNT ведёт себя довольно странно. Если я правильно понимаю, что это должно означать \"количество месяцев с последнего платежа\", то там не должно быть значений меньше 0. А они есть. И есть очень большие значения, больше 1000.\n",
    "\n",
    "experience, тоже почему-то бывает отрицательным, а бывает и очень большим, но это нормально, вероятно.\n",
    "\n",
    "count_mnth_act_passport, опять есть отрицательные значения\n",
    "\n",
    "В категориальных признаках аномалий не обнаружено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Построить логистическую регрессию только на одобренных заявках с преобразованными переменными WoE. Какое значение GINI? F1 мера?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала заполним пропуски на основе отчёта. income заполним нулями, возможно у людей, про которых мы не знаем их доход, он не очень велик. experience заполним нулём как самой популярной категорией, да и пропусков там мало. Пропуски в других категориях просто выделим в отдельную категорию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc.income.fillna(value=0, inplace=True)\n",
    "df_rej.income.fillna(value=0, inplace=True)\n",
    "\n",
    "df_acc.experience.fillna(value=0, inplace=True)\n",
    "df_rej.experience.fillna(value=0, inplace=True)\n",
    "\n",
    "df_all = pd.concat([df_acc, df_rej])\n",
    "\n",
    "df_all.income                  = pd.qcut(df_all.income, q=10, labels=None)\n",
    "df_all.CNT_MNTH_FROM_LAST_PMNT = pd.qcut(df_all.CNT_MNTH_FROM_LAST_PMNT, q=10, labels=None)\n",
    "df_all.age                     = pd.qcut(df_all.age, q=10, labels=None)\n",
    "df_all.experience              = pd.qcut(df_all.experience, q=10, labels=None)\n",
    "df_all.count_mnth_act_passport = pd.qcut(df_all.count_mnth_act_passport, q=10, labels=None)\n",
    "\n",
    "dummies = pd.get_dummies(df_all, columns=df_all.columns.drop('target'), dummy_na=True)\n",
    "df_acc = dummies.iloc[:df_acc.shape[0], :]\n",
    "df_rej = dummies.iloc[df_rej.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "X = df_acc.copy()\n",
    "y = X.target\n",
    "X = X.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=228179, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "WOE_encoder = WOEEncoder()\n",
    "X_train = WOE_encoder.fit_transform(X_train, y_train)\n",
    "X_test = WOE_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_features=\"log2\", max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1:', f1_score(model.predict(X_test), y_test))\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) # roc_auc_score(model.predict(X_test), y_test)\n",
    "Gini = 2 * roc_auc - 1\n",
    "print('ROC AUC:', roc_auc)\n",
    "print('Gini:', Gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Провести анализ Reject Inference. Какая доля отказанных заявок?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим на всей выборке и разметим reject по такому порогу, чтобы доля отказанных заявок была примерно равна оной в accept и была в районе 5-10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "df_pred = df_rej.copy().drop('target', axis=1)\n",
    "df_pred['target'] = model.predict_proba(df_pred)[:, 1]\n",
    "df_pred['target'] = np.where(df_pred['target'] > 0.06, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('доля отказанных заявок в reject:', df_pred[df_pred.target == 1].shape[0] / df_pred[df_pred.target == 0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('доля отказанных заявок в accept:', df_acc[df_acc.target == 1].shape[0] / df_acc[df_acc.target == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 и 3 (продолжение)\n",
    "Наконец после разметки данных посчитаем WoE и Information Value для всех переменных и для всех датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полезные функции\n",
    "\n",
    "# source: https://gist.github.com/dradecic/52d8b2b2213dd3d46f4b75f85c1183f2\n",
    "def calculate_woe_iv(dataset, feature, target, iv=False, sort=False):\n",
    "    lst = []\n",
    "    for i in range(dataset[feature].nunique()):\n",
    "        val = list(dataset[feature].unique())[i]\n",
    "        lst.append({\n",
    "            'Value': val,\n",
    "            'All': dataset[dataset[feature] == val].count()[feature],\n",
    "            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n",
    "            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n",
    "        })\n",
    "        \n",
    "    dset = pd.DataFrame(lst)\n",
    "    dset['Distr_Good'] = dset['Good'] / dset['Good'].sum()\n",
    "    dset['Distr_Bad'] = dset['Bad'] / dset['Bad'].sum()\n",
    "    dset['WoE'] = np.log(dset['Distr_Good'] / dset['Distr_Bad'])\n",
    "    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n",
    "    if sort:\n",
    "        dset = dset.sort_values(by='WoE')\n",
    "        \n",
    "    if iv:\n",
    "        iv = dset['IV'].sum()\n",
    "        return dset, iv\n",
    "    else:\n",
    "        return dset\n",
    "\n",
    "# source: https://www.kaggle.com/puremath86/iv-woe-starter-for-python\n",
    "def woe_iv(dataframe, feature, target='target'):\n",
    "    return (pd.crosstab(dataframe[feature], dataframe[target], normalize='columns')\n",
    "        .assign(WoE = lambda df: np.log(df[1] / df[0])).replace({np.inf: 0, -np.inf: 0})\n",
    "        .assign(IV = lambda df: np.nansum(df.WoE * (df[1] - df[0])))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_pred = df_acc.append(df_pred)\n",
    "for col in list(df_all_pred.columns)[1:]:\n",
    "    try:\n",
    "        print(woe_iv(df_all_pred[cols], col), \"\\n\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Построить логистическую регрессию на всех заявках с преобразованными переменными WoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_all_pred.drop('target', axis=1),\n",
    "                                                    df_all_pred.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=4533357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "WOE_encoder = WOEEncoder()\n",
    "X_train = WOE_encoder.fit_transform(X_train, y_train)\n",
    "X_test = WOE_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1:', f1_score(model.predict(X_test), y_test))\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "Gini = 2 * roc_auc - 1\n",
    "print('ROC AUC:', roc_auc)\n",
    "print('Gini:', Gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Какую модель вы рекомендуете для внедрения в продуктивную среду? Дать развернутое пояснение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая модель получилась лучше по всем использованным метрикам, конечно, среди этих двух я порекомендую её. В целом можно было подойти более подробно к изучению выбросов, разбиению переменные на бины и последующему объединению похожих бинов, подбору гиперпараметров моделей и много чему ещё, но модель и так получилась достаточно хорошей, на мой взгляд"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
